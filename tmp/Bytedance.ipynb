{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56febd-ffd1-4284-ae6e-34e9741a1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def init_embedding(layer: nn.Module) -> NoReturn:\n",
    "    r\"\"\"Initialize a Linear or Convolutional layer.\"\"\"\n",
    "    nn.init.uniform_(layer.weight, -1.0, 1.0)\n",
    "\n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "def init_layer(layer: nn.Module) -> NoReturn:\n",
    "    r\"\"\"Initialize a Linear or Convolutional layer.\"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "def init_bn(bn: nn.Module) -> NoReturn:\n",
    "    r\"\"\"Initialize a Batchnorm layer.\"\"\"\n",
    "    bn.bias.data.fill_(0.0)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "    bn.running_mean.data.fill_(0.0)\n",
    "    bn.running_var.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def act(x: torch.Tensor, activation: str) -> torch.Tensor:\n",
    "\n",
    "    if activation == \"relu\":\n",
    "        return F.relu_(x)\n",
    "\n",
    "    elif activation == \"leaky_relu\":\n",
    "        return F.leaky_relu_(x, negative_slope=0.01)\n",
    "\n",
    "    elif activation == \"swish\":\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Incorrect activation!\")\n",
    "\n",
    "\n",
    "class Base:\n",
    "    def __init__(self):\n",
    "        r\"\"\"Base function for extracting spectrogram, cos, and sin, etc.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def spectrogram(self, input: torch.Tensor, eps: float = 0.0) -> torch.Tensor:\n",
    "        r\"\"\"Calculate spectrogram.\n",
    "        Args:\n",
    "            input: (batch_size, segments_num)\n",
    "            eps: float\n",
    "        Returns:\n",
    "            spectrogram: (batch_size, time_steps, freq_bins)\n",
    "        \"\"\"\n",
    "        (real, imag) = self.stft(input)\n",
    "        return torch.clamp(real ** 2 + imag ** 2, eps, np.inf) ** 0.5\n",
    "\n",
    "    def spectrogram_phase(\n",
    "        self, input: torch.Tensor, eps: float = 0.0\n",
    "    ) -> List[torch.Tensor]:\n",
    "        r\"\"\"Calculate the magnitude, cos, and sin of the STFT of input.\n",
    "        Args:\n",
    "            input: (batch_size, segments_num)\n",
    "            eps: float\n",
    "        Returns:\n",
    "            mag: (batch_size, time_steps, freq_bins)\n",
    "            cos: (batch_size, time_steps, freq_bins)\n",
    "            sin: (batch_size, time_steps, freq_bins)\n",
    "        \"\"\"\n",
    "        (real, imag) = self.stft(input)\n",
    "        mag = torch.clamp(real ** 2 + imag ** 2, eps, np.inf) ** 0.5\n",
    "        cos = real / mag\n",
    "        sin = imag / mag\n",
    "        return mag, cos, sin\n",
    "\n",
    "    def wav_to_spectrogram_phase(\n",
    "        self, input: torch.Tensor, eps: float = 1e-10\n",
    "    ) -> List[torch.Tensor]:\n",
    "        r\"\"\"Convert waveforms to magnitude, cos, and sin of STFT.\n",
    "        Args:\n",
    "            input: (batch_size, channels_num, segment_samples)\n",
    "            eps: float\n",
    "        Outputs:\n",
    "            mag: (batch_size, channels_num, time_steps, freq_bins)\n",
    "            cos: (batch_size, channels_num, time_steps, freq_bins)\n",
    "            sin: (batch_size, channels_num, time_steps, freq_bins)\n",
    "        \"\"\"\n",
    "        batch_size, channels_num, segment_samples = input.shape\n",
    "\n",
    "        # Reshape input with shapes of (n, segments_num) to meet the\n",
    "        # requirements of the stft function.\n",
    "        x = input.reshape(batch_size * channels_num, segment_samples)\n",
    "\n",
    "        mag, cos, sin = self.spectrogram_phase(x, eps=eps)\n",
    "        # mag, cos, sin: (batch_size * channels_num, 1, time_steps, freq_bins)\n",
    "\n",
    "        _, _, time_steps, freq_bins = mag.shape\n",
    "        mag = mag.reshape(batch_size, channels_num, time_steps, freq_bins)\n",
    "        cos = cos.reshape(batch_size, channels_num, time_steps, freq_bins)\n",
    "        sin = sin.reshape(batch_size, channels_num, time_steps, freq_bins)\n",
    "\n",
    "        return mag, cos, sin\n",
    "\n",
    "    def wav_to_spectrogram(\n",
    "        self, input: torch.Tensor, eps: float = 1e-10\n",
    "    ) -> List[torch.Tensor]:\n",
    "\n",
    "        mag, cos, sin = self.wav_to_spectrogram_phase(input, eps)\n",
    "        return mag\n",
    "\n",
    "\n",
    "class Subband:\n",
    "    def __init__(self, subbands_num: int):\n",
    "        r\"\"\"Warning!! This class is not used!!\n",
    "        This class does not work as good as [1] which split subbands in the\n",
    "        time-domain. Please refer to [1] for formal implementation.\n",
    "        [1] Liu, Haohe, et al. \"Channel-wise subband input for better voice and\n",
    "        accompaniment separation on high resolution music.\" arXiv preprint arXiv:2008.05216 (2020).\n",
    "        Args:\n",
    "            subbands_num: int, e.g., 4\n",
    "        \"\"\"\n",
    "        self.subbands_num = subbands_num\n",
    "\n",
    "    def analysis(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        r\"\"\"Analysis time-frequency representation into subbands. Stack the\n",
    "        subbands along the channel axis.\n",
    "        Args:\n",
    "            x: (batch_size, channels_num, time_steps, freq_bins)\n",
    "        Returns:\n",
    "            output: (batch_size, channels_num * subbands_num, time_steps, freq_bins // subbands_num)\n",
    "        \"\"\"\n",
    "        batch_size, channels_num, time_steps, freq_bins = x.shape\n",
    "\n",
    "        x = x.reshape(\n",
    "            batch_size,\n",
    "            channels_num,\n",
    "            time_steps,\n",
    "            self.subbands_num,\n",
    "            freq_bins // self.subbands_num,\n",
    "        )\n",
    "        # x: (batch_size, channels_num, time_steps, subbands_num, freq_bins // subbands_num)\n",
    "\n",
    "        x = x.transpose(2, 3)\n",
    "\n",
    "        output = x.reshape(\n",
    "            batch_size,\n",
    "            channels_num * self.subbands_num,\n",
    "            time_steps,\n",
    "            freq_bins // self.subbands_num,\n",
    "        )\n",
    "        # output: (batch_size, channels_num * subbands_num, time_steps, freq_bins // subbands_num)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def synthesis(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        r\"\"\"Synthesis subband time-frequency representations into original\n",
    "        time-frequency representation.\n",
    "        Args:\n",
    "            x: (batch_size, channels_num * subbands_num, time_steps, freq_bins // subbands_num)\n",
    "        Returns:\n",
    "            output: (batch_size, channels_num, time_steps, freq_bins)\n",
    "        \"\"\"\n",
    "        batch_size, subband_channels_num, time_steps, subband_freq_bins = x.shape\n",
    "\n",
    "        channels_num = subband_channels_num // self.subbands_num\n",
    "        freq_bins = subband_freq_bins * self.subbands_num\n",
    "\n",
    "        x = x.reshape(\n",
    "            batch_size,\n",
    "            channels_num,\n",
    "            self.subbands_num,\n",
    "            time_steps,\n",
    "            subband_freq_bins,\n",
    "        )\n",
    "        # x: (batch_size, channels_num, subbands_num, time_steps, freq_bins // subbands_num)\n",
    "\n",
    "        x = x.transpose(2, 3)\n",
    "        # x: (batch_size, channels_num, time_steps, subbands_num, freq_bins // subbands_num)\n",
    "\n",
    "        output = x.reshape(batch_size, channels_num, time_steps, freq_bins)\n",
    "        # x: (batch_size, channels_num, time_steps, freq_bins)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5940ea30-e9ba-4b6f-8309-13e126690cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlockRes(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, activation, momentum):\n",
    "        r\"\"\"Residual block.\"\"\"\n",
    "        super(ConvBlockRes, self).__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        padding = [kernel_size[0] // 2, kernel_size[1] // 2]\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels, momentum=momentum)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels, momentum=momentum)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=(1, 1),\n",
    "            dilation=(1, 1),\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=(1, 1),\n",
    "            dilation=(1, 1),\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=(1, 1),\n",
    "                stride=(1, 1),\n",
    "                padding=(0, 0),\n",
    "            )\n",
    "\n",
    "            self.is_shortcut = True\n",
    "        else:\n",
    "            self.is_shortcut = False\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "\n",
    "        if self.is_shortcut:\n",
    "            init_layer(self.shortcut)\n",
    "\n",
    "    def forward(self, x):\n",
    "        origin = x\n",
    "        x = self.conv1(act(self.bn1(x), self.activation))\n",
    "        x = self.conv2(act(self.bn2(x), self.activation))\n",
    "\n",
    "        if self.is_shortcut:\n",
    "            return self.shortcut(origin) + x\n",
    "        else:\n",
    "            return origin + x\n",
    "\n",
    "\n",
    "class EncoderBlockRes4B(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, downsample, activation, momentum\n",
    "    ):\n",
    "        r\"\"\"Encoder block, contains 8 convolutional layers.\"\"\"\n",
    "        super(EncoderBlockRes4B, self).__init__()\n",
    "\n",
    "        self.conv_block1 = ConvBlockRes(\n",
    "            in_channels, out_channels, kernel_size, activation, momentum\n",
    "        )\n",
    "        self.conv_block2 = ConvBlockRes(\n",
    "            out_channels, out_channels, kernel_size, activation, momentum\n",
    "        )\n",
    "        self.conv_block3 = ConvBlockRes(\n",
    "            out_channels, out_channels, kernel_size, activation, momentum\n",
    "        )\n",
    "        self.conv_block4 = ConvBlockRes(\n",
    "            out_channels, out_channels, kernel_size, activation, momentum\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder = self.conv_block1(x)\n",
    "        encoder = self.conv_block2(encoder)\n",
    "        encoder = self.conv_block3(encoder)\n",
    "        encoder = self.conv_block4(encoder)\n",
    "        encoder_pool = F.avg_pool2d(encoder, kernel_size=self.downsample)\n",
    "        return encoder_pool, encoder\n",
    "\n",
    "\n",
    "class DecoderBlockRes4B(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, upsample, activation, momentum\n",
    "    ):\n",
    "        r\"\"\"Decoder block, contains 1 transpose convolutional and 8 convolutional layers.\"\"\"\n",
    "        super(DecoderBlockRes4B, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = upsample\n",
    "        self.activation = activation\n",
    "\n",
    "        self.conv1 = torch.nn.ConvTranspose2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=self.stride,\n",
    "            stride=self.stride,\n",
    "            padding=(0, 0),\n",
    "            bias=False,\n",
    "            dilation=(1, 1),\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels, momentum=momentum)\n",
    "        self.conv_block2 = ConvBlockRes(\n",
    "            out_channels * 2, out_channels, kernel_size, activation, momentum\n",
    "        )\n",
    "        self.conv_block3 = ConvBlockRes(\n",
    "            out_channels, out_channels, kernel_size, activation, momentum\n",
    "        )\n",
    "        self.conv_block4 = ConvBlockRes(\n",
    "            out_channels, out_channels, kernel_size, activation, momentum\n",
    "        )\n",
    "        self.conv_block5 = ConvBlockRes(\n",
    "            out_channels, out_channels, kernel_size, activation, momentum\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_bn(self.bn1)\n",
    "        init_layer(self.conv1)\n",
    "\n",
    "    def forward(self, input_tensor, concat_tensor):\n",
    "        x = self.conv1(act(self.bn1(input_tensor), self.activation))\n",
    "        x = torch.cat((x, concat_tensor), dim=1)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.conv_block5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResUNet143_DecouplePlus(nn.Module, Base):\n",
    "    def __init__(self, input_channels, target_sources_num):\n",
    "        super(ResUNet143_DecouplePlus, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.target_sources_num = target_sources_num\n",
    "\n",
    "        window_size = 2048\n",
    "        hop_size = 441\n",
    "        center = True\n",
    "        pad_mode = \"reflect\"\n",
    "        window = \"hann\"\n",
    "        activation = \"relu\"\n",
    "        momentum = 0.01\n",
    "\n",
    "        self.subbands_num = 4\n",
    "        self.K = 4  # outputs: |M|, cos∠M, sin∠M, |M2|\n",
    "\n",
    "        self.downsample_ratio = 2 ** 6  # This number equals 2^{#encoder_blcoks}\n",
    "\n",
    "        self.stft = STFT(\n",
    "            n_fft=window_size,\n",
    "            hop_length=hop_size,\n",
    "            win_length=window_size,\n",
    "            window=window,\n",
    "            center=center,\n",
    "            pad_mode=pad_mode,\n",
    "            freeze_parameters=True,\n",
    "        )\n",
    "\n",
    "        self.istft = ISTFT(\n",
    "            n_fft=window_size,\n",
    "            hop_length=hop_size,\n",
    "            win_length=window_size,\n",
    "            window=window,\n",
    "            center=center,\n",
    "            pad_mode=pad_mode,\n",
    "            freeze_parameters=True,\n",
    "        )\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(window_size // 2 + 1, momentum=momentum)\n",
    "\n",
    "        self.subband = Subband(subbands_num=self.subbands_num)\n",
    "\n",
    "        self.encoder_block1 = EncoderBlockRes4B(\n",
    "            in_channels=input_channels * self.subbands_num,\n",
    "            out_channels=32,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(2, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.encoder_block2 = EncoderBlockRes4B(\n",
    "            in_channels=32,\n",
    "            out_channels=64,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(2, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.encoder_block3 = EncoderBlockRes4B(\n",
    "            in_channels=64,\n",
    "            out_channels=128,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(2, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.encoder_block4 = EncoderBlockRes4B(\n",
    "            in_channels=128,\n",
    "            out_channels=256,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(2, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.encoder_block5 = EncoderBlockRes4B(\n",
    "            in_channels=256,\n",
    "            out_channels=384,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(2, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.encoder_block6 = EncoderBlockRes4B(\n",
    "            in_channels=384,\n",
    "            out_channels=384,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(1, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.conv_block7a = EncoderBlockRes4B(\n",
    "            in_channels=384,\n",
    "            out_channels=384,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(1, 1),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.conv_block7b = EncoderBlockRes4B(\n",
    "            in_channels=384,\n",
    "            out_channels=384,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(1, 1),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.conv_block7c = EncoderBlockRes4B(\n",
    "            in_channels=384,\n",
    "            out_channels=384,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(1, 1),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.conv_block7d = EncoderBlockRes4B(\n",
    "            in_channels=384,\n",
    "            out_channels=384,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(1, 1),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.decoder_block1 = DecoderBlockRes4B(\n",
    "            in_channels=384,\n",
    "            out_channels=384,\n",
    "            kernel_size=(3, 3),\n",
    "            upsample=(1, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.decoder_block2 = DecoderBlockRes4B(\n",
    "            in_channels=384,\n",
    "            out_channels=384,\n",
    "            kernel_size=(3, 3),\n",
    "            upsample=(2, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.decoder_block3 = DecoderBlockRes4B(\n",
    "            in_channels=384,\n",
    "            out_channels=256,\n",
    "            kernel_size=(3, 3),\n",
    "            upsample=(2, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.decoder_block4 = DecoderBlockRes4B(\n",
    "            in_channels=256,\n",
    "            out_channels=128,\n",
    "            kernel_size=(3, 3),\n",
    "            upsample=(2, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.decoder_block5 = DecoderBlockRes4B(\n",
    "            in_channels=128,\n",
    "            out_channels=64,\n",
    "            kernel_size=(3, 3),\n",
    "            upsample=(2, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        self.decoder_block6 = DecoderBlockRes4B(\n",
    "            in_channels=64,\n",
    "            out_channels=32,\n",
    "            kernel_size=(3, 3),\n",
    "            upsample=(2, 2),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "\n",
    "        self.after_conv_block1 = EncoderBlockRes4B(\n",
    "            in_channels=32,\n",
    "            out_channels=32,\n",
    "            kernel_size=(3, 3),\n",
    "            downsample=(1, 1),\n",
    "            activation=activation,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "\n",
    "        self.after_conv2 = nn.Conv2d(\n",
    "            in_channels=32,\n",
    "            out_channels=input_channels\n",
    "            * self.subbands_num\n",
    "            * target_sources_num\n",
    "            * self.K,\n",
    "            kernel_size=(1, 1),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.after_conv2)\n",
    "\n",
    "    def feature_maps_to_wav(\n",
    "        self,\n",
    "        input_tensor: torch.Tensor,\n",
    "        sp: torch.Tensor,\n",
    "        sin_in: torch.Tensor,\n",
    "        cos_in: torch.Tensor,\n",
    "        audio_length: int,\n",
    "    ) -> torch.Tensor:\n",
    "        r\"\"\"Convert feature maps to waveform.\n",
    "        Args:\n",
    "            input_tensor: (batch_size, feature_maps, time_steps, freq_bins)\n",
    "            sp: (batch_size, feature_maps, time_steps, freq_bins)\n",
    "            sin_in: (batch_size, feature_maps, time_steps, freq_bins)\n",
    "            cos_in: (batch_size, feature_maps, time_steps, freq_bins)\n",
    "        Outputs:\n",
    "            waveform: (batch_size, target_sources_num * input_channels, segment_samples)\n",
    "        \"\"\"\n",
    "        batch_size, _, time_steps, freq_bins = input_tensor.shape\n",
    "\n",
    "        x = input_tensor.reshape(\n",
    "            batch_size,\n",
    "            self.target_sources_num,\n",
    "            self.input_channels,\n",
    "            self.K,\n",
    "            time_steps,\n",
    "            freq_bins,\n",
    "        )\n",
    "        # x: (batch_size, target_sources_num, input_channles, K, time_steps, freq_bins)\n",
    "\n",
    "        mask_mag = torch.sigmoid(x[:, :, :, 0, :, :])\n",
    "        _mask_real = torch.tanh(x[:, :, :, 1, :, :])\n",
    "        _mask_imag = torch.tanh(x[:, :, :, 2, :, :])\n",
    "        linear_mag = x[:, :, :, 3, :, :]\n",
    "        _, mask_cos, mask_sin = magphase(_mask_real, _mask_imag)\n",
    "        # mask_cos, mask_sin: (batch_size, target_sources_num, input_channles, time_steps, freq_bins)\n",
    "\n",
    "        # Y = |Y|cos∠Y + j|Y|sin∠Y\n",
    "        #   = |Y|cos(∠X + ∠M) + j|Y|sin(∠X + ∠M)\n",
    "        #   = |Y|(cos∠X cos∠M - sin∠X sin∠M) + j|Y|(sin∠X cos∠M + cos∠X sin∠M)\n",
    "        out_cos = (\n",
    "            cos_in[:, None, :, :, :] * mask_cos - sin_in[:, None, :, :, :] * mask_sin\n",
    "        )\n",
    "        out_sin = (\n",
    "            sin_in[:, None, :, :, :] * mask_cos + cos_in[:, None, :, :, :] * mask_sin\n",
    "        )\n",
    "        # out_cos: (batch_size, target_sources_num, input_channles, time_steps, freq_bins)\n",
    "        # out_sin: (batch_size, target_sources_num, input_channles, time_steps, freq_bins)\n",
    "\n",
    "        # Calculate |Y|.\n",
    "        out_mag = F.relu_(sp[:, None, :, :, :] * mask_mag + linear_mag)\n",
    "        # out_mag: (batch_size, target_sources_num, input_channles, time_steps, freq_bins)\n",
    "\n",
    "        # Calculate Y_{real} and Y_{imag} for ISTFT.\n",
    "        out_real = out_mag * out_cos\n",
    "        out_imag = out_mag * out_sin\n",
    "        # out_real, out_imag: (batch_size, target_sources_num, input_channles, time_steps, freq_bins)\n",
    "\n",
    "        # Reformat shape to (n, 1, time_steps, freq_bins) for ISTFT.\n",
    "        shape = (\n",
    "            batch_size * self.target_sources_num * self.input_channels,\n",
    "            1,\n",
    "            time_steps,\n",
    "            freq_bins,\n",
    "        )\n",
    "        out_real = out_real.reshape(shape)\n",
    "        out_imag = out_imag.reshape(shape)\n",
    "\n",
    "        # ISTFT.\n",
    "        x = self.istft(out_real, out_imag, audio_length)\n",
    "        # (batch_size * target_sources_num * input_channels, segments_num)\n",
    "\n",
    "        # Reshape.\n",
    "        waveform = x.reshape(\n",
    "            batch_size, self.target_sources_num * self.input_channels, audio_length\n",
    "        )\n",
    "        # (batch_size, target_sources_num * input_channels, segments_num)\n",
    "\n",
    "        return waveform\n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            input: (batch_size, channels_num, segment_samples)\n",
    "        Outputs:\n",
    "            output_dict: {\n",
    "                'wav': (batch_size, channels_num, segment_samples)\n",
    "            }\n",
    "        \"\"\"\n",
    "        mixtures = input_dict['waveform']\n",
    "        # (batch_size, input_channels, segment_samples)\n",
    "\n",
    "        mag, cos_in, sin_in = self.wav_to_spectrogram_phase(mixtures)\n",
    "        # mag, cos_in, sin_in: (batch_size, input_channels, time_steps, freq_bins)\n",
    "\n",
    "        # Batch normalize on individual frequency bins.\n",
    "        x = mag.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \"\"\"(batch_size, input_channels, time_steps, freq_bins)\"\"\"\n",
    "\n",
    "        # Pad spectrogram to be evenly divided by downsample ratio.\n",
    "        origin_len = x.shape[2]\n",
    "        pad_len = (\n",
    "            int(np.ceil(x.shape[2] / self.downsample_ratio)) * self.downsample_ratio\n",
    "            - origin_len\n",
    "        )\n",
    "        x = F.pad(x, pad=(0, 0, 0, pad_len))\n",
    "        \"\"\"(batch_size, input_channels, padded_time_steps, freq_bins)\"\"\"\n",
    "\n",
    "        # Let frequency bins be evenly divided by 2, e.g., 1025 -> 1024\n",
    "        x = x[..., 0 : x.shape[-1] - 1]  # (bs, input_channels, T, F)\n",
    "\n",
    "        x = self.subband.analysis(x)\n",
    "        # (bs, input_channels, T, F'), where F' = F // subbands_num\n",
    "\n",
    "        # UNet\n",
    "        (x1_pool, x1) = self.encoder_block1(x)  # x1_pool: (bs, 32, T / 2, F / 2)\n",
    "        (x2_pool, x2) = self.encoder_block2(x1_pool)  # x2_pool: (bs, 64, T / 4, F / 4)\n",
    "        (x3_pool, x3) = self.encoder_block3(x2_pool)  # x3_pool: (bs, 128, T / 8, F / 8)\n",
    "        (x4_pool, x4) = self.encoder_block4(\n",
    "            x3_pool\n",
    "        )  # x4_pool: (bs, 256, T / 16, F / 16)\n",
    "        (x5_pool, x5) = self.encoder_block5(\n",
    "            x4_pool\n",
    "        )  # x5_pool: (bs, 384, T / 32, F / 32)\n",
    "        (x6_pool, x6) = self.encoder_block6(\n",
    "            x5_pool\n",
    "        )  # x6_pool: (bs, 384, T / 32, F / 64)\n",
    "        (x_center, _) = self.conv_block7a(x6_pool)  # (bs, 384, T / 32, F / 64)\n",
    "        (x_center, _) = self.conv_block7b(x_center)  # (bs, 384, T / 32, F / 64)\n",
    "        (x_center, _) = self.conv_block7c(x_center)  # (bs, 384, T / 32, F / 64)\n",
    "        (x_center, _) = self.conv_block7d(x_center)  # (bs, 384, T / 32, F / 64)\n",
    "        x7 = self.decoder_block1(x_center, x6)  # (bs, 384, T / 32, F / 32)\n",
    "        x8 = self.decoder_block2(x7, x5)  # (bs, 384, T / 16, F / 16)\n",
    "        x9 = self.decoder_block3(x8, x4)  # (bs, 256, T / 8, F / 8)\n",
    "        x10 = self.decoder_block4(x9, x3)  # (bs, 128, T / 4, F / 4)\n",
    "        x11 = self.decoder_block5(x10, x2)  # (bs, 64, T / 2, F / 2)\n",
    "        x12 = self.decoder_block6(x11, x1)  # (bs, 32, T, F)\n",
    "        (x, _) = self.after_conv_block1(x12)  # (bs, 32, T, F)\n",
    "\n",
    "        x = self.after_conv2(x)  # (bs, channels * 3, T, F)\n",
    "        # (batch_size, input_channles * subbands_num * targets_num * k, T, F')\n",
    "\n",
    "        x = self.subband.synthesis(x)\n",
    "        # (batch_size, input_channles * targets_num * K, T, F)\n",
    "\n",
    "        # Recover shape\n",
    "        x = F.pad(x, pad=(0, 1))  # Pad frequency, e.g., 1024 -> 1025.\n",
    "        x = x[:, :, 0:origin_len, :]  # (bs, feature_maps, time_steps, freq_bins)\n",
    "\n",
    "        audio_length = mixtures.shape[2]\n",
    "\n",
    "        separated_audio = self.feature_maps_to_wav(x, mag, sin_in, cos_in, audio_length)\n",
    "        # separated_audio: (batch_size, target_sources_num * input_channels, segments_num)\n",
    "\n",
    "        output_dict = {'waveform': separated_audio}\n",
    "\n",
    "        return output_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
