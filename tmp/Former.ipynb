{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c107c843-817c-4cc4-8971-2b739faf30ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbh/.conda/envs/dnn/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.activation import MultiheadAttention\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d5886-c49e-43bc-ba65-5d60e08d9bf2",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f35281-f75d-4339-8098-b81636c87685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 257, 32])\n",
      "enc_1 : torch.Size([2, 8, 128, 32]) | 1024\n",
      "enc_2 : torch.Size([2, 16, 64, 32]) | 1024\n",
      "enc_3 : torch.Size([2, 32, 32, 32]) | 1024\n",
      "enc_4 : torch.Size([2, 64, 16, 32]) | 1024\n",
      "enc_5 : torch.Size([2, 128, 8, 32]) | 1024\n",
      "enc_6 : torch.Size([2, 256, 4, 32]) | 1024\n",
      "enc_7 : torch.Size([2, 512, 2, 32]) | 1024\n",
      "enc_8 : torch.Size([2, 1024, 1, 32]) | 1024\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, C, L, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.C = C # in_channels\n",
    "        self.L = L  # length_kernel\n",
    "        self.N = N  # n_output\n",
    "        self.conv = nn.Conv2d(in_channels=C,\n",
    "                                out_channels=N,\n",
    "                                kernel_size=(L,1),\n",
    "                                stride=(L,1),\n",
    "                                padding=0,\n",
    "                                bias=False)\n",
    "        self.activation = nn.PReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "x = torch.rand(2,5,257,32)\n",
    "print(x.shape)\n",
    "m = []\n",
    "m.append(Encoder(C=5,N=8,L=2))\n",
    "m.append(Encoder(C=8,N=16,L=2))\n",
    "m.append(Encoder(C=16,N=32,L=2))\n",
    "m.append(Encoder(C=32,N=64,L=2))\n",
    "m.append(Encoder(C=64,N=128,L=2))\n",
    "m.append(Encoder(C=128,N=256,L=2))\n",
    "m.append(Encoder(C=256,N=512,L=2))\n",
    "m.append(Encoder(C=512,N=1024,L=2))\n",
    "\n",
    "for i in range(len(m)) : \n",
    "    x = m[i](x)\n",
    "    print(\"enc_{} : {} | {}\".format(i+1,x.shape, x.shape[1]*x.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16bb499a-424d-4dab-b0bd-b703f163ddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 512])\n",
      "torch.Size([10, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "class TransformerEncoderLayer(Module):\n",
    "    \"\"\"\n",
    "        https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerEncoderLayer\n",
    "    \n",
    "        TransformerEncoderLayer is made up of self-attn and feedforward network.\n",
    "        This standard encoder layer is based on the paper \"Attention Is All You Need\".\n",
    "        Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n",
    "        Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in\n",
    "        Neural Information Processing Systems, pages 6000-6010. Users may modify or implement\n",
    "        in a different way during application.\n",
    "        Args:\n",
    "            d_model: the number of expected features in the input (required).\n",
    "            nhead: the number of heads in the multiheadattention models (required).\n",
    "            dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
    "            dropout: the dropout value (default=0.1).\n",
    "            activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
    "        Examples:\n",
    "            >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "            >>> src = torch.rand(10, 32, 512)\n",
    "            >>> out = encoder_layer(src)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, n_head, dropout=0):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.LayerNorm1 = nn.LayerNorm(normalized_shape=d_model)\n",
    "        self.self_attn = MultiheadAttention(d_model, n_head, dropout=dropout)\n",
    "        self.Dropout1 = nn.Dropout(p=dropout)\n",
    "        self.LayerNorm2 = nn.LayerNorm(normalized_shape=d_model)\n",
    "        self.FeedForward = nn.Sequential(nn.Linear(d_model, d_model*2*2),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout(p=dropout),\n",
    "                                         nn.Linear(d_model*2*2, d_model))\n",
    "        self.Dropout2 = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z1 = self.LayerNorm1(z)\n",
    "        z2 = self.self_attn(z1, z1, z1, attn_mask=None, key_padding_mask=None)[0]\n",
    "        z3 = self.Dropout1(z2) + z\n",
    "        z4 = self.LayerNorm2(z3)\n",
    "        z5 = self.Dropout2(self.FeedForward(z4)) + z3\n",
    "        return z5\n",
    "    \n",
    "x = torch.rand(10, 32, 512)\n",
    "m = TransformerEncoderLayer(d_model=512, n_head=8)\n",
    "\n",
    "print(x.shape)\n",
    "y = m(x)    \n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e53553a-8c07-4c81-bf27-d0e8f38717a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 1024])\n",
      "torch.Size([2, 2, 1024])\n",
      "torch.Size([2, 32, 1024])\n",
      "torch.Size([2, 2, 1024])\n"
     ]
    }
   ],
   "source": [
    "class RNN(Module):\n",
    "    def __init__(self, C, hidden_size= 1024,  num_layers=2):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size = C, hidden_size = hidden_size, num_layers = num_layers, batch_first  = True, bidirectional  = False)\n",
    "        self.activation = nn.PReLU()\n",
    "        self.FC = nn.Linear(hidden_size,C)\n",
    "    def forward(self, x, h = None):\n",
    "        \n",
    "        x,h_out = self.rnn(x,h)\n",
    "        x = self.activation(x)\n",
    "        x = self.FC(x)\n",
    "        return x,h_out\n",
    "    \n",
    "x = torch.rand(2, 32, 1024)\n",
    "m = RNN(1024)\n",
    "y,h = m(x)\n",
    "print(y.shape)\n",
    "print(h.shape)\n",
    "\n",
    "y,h = m(x,h)\n",
    "print(y.shape)\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2d44f46-7c22-4cdf-8c31-bcfe54e41b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 257, 32])\n",
      "x : torch.Size([2, 1024, 1, 32])\n",
      "x : torch.Size([2, 1024, 32])\n",
      "x : torch.Size([2, 32, 1024])\n",
      "w : torch.Size([2, 32, 1028])\n",
      "w : torch.Size([2, 1028, 32])\n",
      "torch.Size([2, 257, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "class Model_v1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_v1, self).__init__()\n",
    "        n_fft = 512\n",
    "        n_hfft = 257\n",
    "\n",
    "        # Convolution Encoders\n",
    "        self.encoders = []\n",
    "        self.encoders.append(Encoder(C=5,N=8,L=2))\n",
    "        for i in range(1,8):\n",
    "            self.encoders.append(Encoder(C=2**(i+2),N=2**(i+3),L=2))\n",
    "    \n",
    "        # Transformer Encoder\n",
    "        self.formers = []\n",
    "        self.formers.append(TransformerEncoderLayer(d_model=1024,n_head=8))\n",
    "        self.formers.append(TransformerEncoderLayer(d_model=1024,n_head=8))\n",
    "        \n",
    "        self.recurrents = []\n",
    "        self.recurrents.append(RNN(1024))\n",
    "        self.recurrents.append(RNN(1024))\n",
    "        \n",
    "        self.output = nn.Linear(1024,257*4)\n",
    "\n",
    "    def forward(self,x):\n",
    "        for enc in self.encoders : \n",
    "            x = enc(x)\n",
    "        \n",
    "        # x : [B, 1024,1,T]\n",
    "        print(\"x : {}\".format(x.shape))\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[1],x.shape[3]))\n",
    "        print(\"x : {}\".format(x.shape))\n",
    "        x = torch.permute(x,(0,2,1))\n",
    "        print(\"x : {}\".format(x.shape))\n",
    "\n",
    "        for former in self.formers : \n",
    "            x = former(x)\n",
    "        \n",
    "        for recurrent in self.recurrents : \n",
    "            x,h = recurrent(x)\n",
    "        \n",
    "        w = self.output(x)\n",
    "        print(\"w : {}\".format(w.shape))\n",
    "        w = torch.permute(w,(0,2,1))\n",
    "        print(\"w : {}\".format(w.shape))\n",
    "        w = torch.reshape(w,(w.shape[0],257,4,w.shape[-1]))\n",
    "        return w\n",
    "            \n",
    "x = torch.rand(2,5,257,32)\n",
    "print(x.shape)\n",
    "\n",
    "m = Model_v1()\n",
    "\n",
    "y = m(x)    \n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6ad98-9d07-4817-b33e-0f9ff3274a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
