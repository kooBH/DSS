{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1c658443-7331-4421-bff6-9dcee35e0ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# force re-import\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "9f3e772a-c7c6-4ed7-9973-3c900e76da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 257, 126])\n",
      "torch.Size([2, 4, 257, 126])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found ComplexFloat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [251]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m x  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(B,C,\u001b[38;5;241m16000\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m angle \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mrand(B)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m360\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmic_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/dnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/DSS/src/Attractor/Attractor.py:421\u001b[0m, in \u001b[0;36mDirectionAttractorNet.forward\u001b[0;34m(self, x, angle, mic_pos)\u001b[0m\n\u001b[1;32m    417\u001b[0m spectral_feauture \u001b[38;5;241m=\u001b[39m spectral_feauture\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m#print(\"spectral_feature : {}, angle {}\".format(spectral_feauture.shape,angle.shape))\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m M_s,v_s,M_n,v_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectral_feauture\u001b[49m\u001b[43m,\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_out(X,a,M_s,v_s,M_n,v_n)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# into batchs\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/DSS/src/Attractor/Attractor.py:202\u001b[0m, in \u001b[0;36mDirectionAttractor.forward\u001b[0;34m(self, spectral_feature, angle)\u001b[0m\n\u001b[1;32m    200\u001b[0m B \u001b[38;5;241m=\u001b[39m spectral_feature\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    201\u001b[0m T \u001b[38;5;241m=\u001b[39m spectral_feature\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 202\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectral_feature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m a_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mZ_s(angle)\n\u001b[1;32m    204\u001b[0m a_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mZ_n(angle)\n",
      "File \u001b[0;32m~/.conda/envs/dnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/DSS/src/Attractor/Attractor.py:81\u001b[0m, in \u001b[0;36mencoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder)) :\n\u001b[0;32m---> 81\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macitvation[i](x)\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m :\n",
      "File \u001b[0;32m~/.conda/envs/dnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/dnn/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found ComplexFloat"
     ]
    }
   ],
   "source": [
    "from Attractor import DirectionAttractorNet\n",
    "\n",
    "B = 2\n",
    "C = 4\n",
    "mic_pos = [[0,0,0],[1,0,0],[0,1,0],[1,1,0]]\n",
    "\n",
    "m = DirectionAttractorNet().to(\"cuda:0\")\n",
    "\n",
    "x  = torch.rand(B,C,16000).to(\"cuda:0\")\n",
    "angle = (torch.rand(B)*360).to(\"cuda:0\")\n",
    "y = m(x,angle,torch.tensor(mic_pos).unsqueeze(0).to(\"cuda:0\"))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e35ae08d-bf43-40b4-b32b-0a33b141c94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0,3)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a0826-27ab-48dc-a48b-8aa647bed315",
   "metadata": {},
   "source": [
    "# Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0cf6d188-8e50-4f07-9b14-ec3d6e4febe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== input == \n",
      "X : torch.Size([2, 3, 4, 5])\n",
      "M : torch.Size([2, 4, 5])\n",
      "v : torch.Size([2, 1, 5])\n",
      "== batchwise == \n",
      "X : torch.Size([40, 3, 1])\n",
      "M : torch.Size([40, 1, 1])\n",
      "v : torch.Size([40, 1, 1])\n",
      "R : torch.Size([40, 3, 3])\n",
      "torch.Size([40, 3, 3])\n",
      "torch.Size([40, 3, 3])\n",
      "torch.Size([40, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "B = 2\n",
    "C = 3\n",
    "F = 4\n",
    "T = 5\n",
    "\n",
    "X = torch.rand(B,C,F,T,dtype=torch.cfloat)*2-1\n",
    "M = torch.rand(B,F,T)\n",
    "v = torch.rand(B,1,T)\n",
    "\n",
    "print(\"== input == \")\n",
    "print(\"X : {}\".format(X.shape))\n",
    "print(\"M : {}\".format(M.shape))\n",
    "print(\"v : {}\".format(v.shape))\n",
    "\n",
    "#print(M)\n",
    "#print(v)\n",
    "\n",
    "# X * X^H\n",
    "\n",
    "X__ = torch.permute(X,(0,2,3,1))\n",
    "X__ = torch.reshape(X__,(B*F*T,C,1))\n",
    "M__ = torch.reshape(M,(B*F*T,1,1))\n",
    "v__ = v.expand(B,F,T)\n",
    "v__ = torch.reshape(v__,(B*F*T,1,1))\n",
    "print(\"== batchwise == \")\n",
    "print(\"X : {}\".format(X__.shape))\n",
    "print(\"M : {}\".format(M__.shape))\n",
    "print(\"v : {}\".format(v__.shape))\n",
    "\n",
    "#print(M__)\n",
    "#print(v__)\n",
    "\n",
    "R = torch.bmm(X__,torch.permute(X__,(0,2,1)))\n",
    "print(\"R : {}\".format(R.shape))\n",
    "# masking\n",
    "R *= v__\n",
    "R *= M__\n",
    "\n",
    "R = R + torch.eye(C)*1e-4\n",
    "\n",
    "R_inv =  torch.inverse(R)\n",
    "\n",
    "#R = torch.reshape(R,(B,F,T,C,C))\n",
    "\n",
    "print(R.shape)\n",
    "print(R_inv.shape)\n",
    "\n",
    "W = torch.bmm(R,R_inv)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "29ab1836-d483-402a-8c37-d04ff9f54474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000e+00,  5.5879e-09, -5.9605e-08,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+00,  5.9605e-08, -5.9605e-08],\n",
       "         [ 5.9605e-08,  3.5390e-08,  1.0000e+00,  0.0000e+00],\n",
       "         [-1.5646e-07, -5.0757e-08, -7.4506e-08,  1.0000e+00]],\n",
       "\n",
       "        [[ 1.0000e+00,  1.7881e-07,  0.0000e+00,  7.1526e-07],\n",
       "         [-1.4901e-07,  1.0000e+00,  4.7684e-07,  7.1526e-07],\n",
       "         [-2.9802e-08,  5.9605e-08,  1.0000e+00,  1.1921e-07],\n",
       "         [ 2.9802e-08, -1.4901e-08,  1.1921e-07,  1.0000e+00]],\n",
       "\n",
       "        [[ 1.0000e+00,  7.1526e-07,  4.7684e-07, -9.5367e-07],\n",
       "         [-1.9073e-06,  1.0000e+00,  0.0000e+00, -4.7684e-07],\n",
       "         [-2.8610e-06,  0.0000e+00,  1.0000e+00,  4.7684e-07],\n",
       "         [-2.3842e-06,  7.1526e-07,  0.0000e+00,  1.0000e+00]]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3,4,4)\n",
    "x_inv = torch.inverse(x)\n",
    "torch.bmm(x,x_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4a7a7f53-d07d-4833-a5e9-f962703bbb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3625+0.4254j],\n",
      "        [0.4639+0.6417j],\n",
      "        [0.7367+0.2248j]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3124-9.7332e-10j, 0.4411-3.5302e-02j, 0.3627+2.3188e-01j],\n",
       "        [0.4411+3.5302e-02j, 0.6270-1.1783e-08j, 0.4860+3.6847e-01j],\n",
       "        [0.3627-2.3188e-01j, 0.4860-3.6847e-01j, 0.5932-6.2595e-09j]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.rand(3,1,dtype=torch.cfloat)\n",
    "print(C)\n",
    "\n",
    "torch.matmul(C,C.H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fbfb89-bf18-4a11-8dce-8d40603b1add",
   "metadata": {},
   "source": [
    "## Batch Beamforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "967817d8-6aa6-4655-ba5d-9d03d96baf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1eef478f-b9d3-47c0-a677-fdd18e6407be",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "C = 3\n",
    "F = 4\n",
    "T = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0b6be-3bce-41f6-a3bb-3b55303847ce",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{w}(f) = \\frac{\\mathbf{R_u}^{-1}(f)\\mathbf{h}(f)}{\\mathbf{h}^H(f)\\mathbf{R_u}^{-1}(f)\\mathbf{h}(f)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "79094847-7f26-489b-bcda-f5e59a8a2f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 3, 1])\n",
      "torch.Size([40, 1, 3])\n",
      "torch.Size([40, 3, 3])\n",
      "torch.Size([40, 3, 3])\n",
      "torch.Size([40, 3, 1])\n",
      "torch.Size([40, 1, 1])\n",
      "torch.Size([40, 3, 1])\n",
      "torch.Size([40, 1, 3])\n",
      "torch.Size([40, 1, 1])\n",
      "torch.Size([2, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(B,C,F,T)\n",
    "h = torch.rand(B,C,F,T)\n",
    "R = torch.rand(B,C,C,F,T)\n",
    "\n",
    "bh = torch.permute(h,(0,2,3,1))\n",
    "bh = torch.reshape(bh,(B*F*T,C,1))\n",
    "print(bh.shape)\n",
    "\n",
    "bhT = torch.transpose(bh,1,2)\n",
    "print(bhT.shape)\n",
    "\n",
    "bR = torch.permute(R,(0,3,4,1,2))\n",
    "bR = torch.reshape(bR,(B*F*T,C,C))\n",
    "print(bR.shape)\n",
    "\n",
    "bR_inv = torch.inverse(bR)\n",
    "print(bR_inv.shape)\n",
    "\n",
    "numer = torch.bmm(bR_inv,bh)\n",
    "denom = torch.bmm(torch.bmm(bhT,bR_inv),bh)\n",
    "\n",
    "print(numer.shape)\n",
    "print(denom.shape)\n",
    "\n",
    "bw = numer/denom\n",
    "print(bw.shape)\n",
    "\n",
    "bX = torch.permute(X,(0,2,3,1))\n",
    "bX = torch.reshape(bX,(B*F*T,1,C))\n",
    "print(bX.shape)\n",
    "\n",
    "bY = torch.bmm(bX,bw)\n",
    "print(bY.shape)\n",
    "\n",
    "Y = torch.reshape(bY,(B,F,T))\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "97b03cd7-5a90-4a36-ad31-921278a63474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0591, 0.1539, 0.9029, 0.2346],\n",
      "        [0.5424, 0.7434, 0.9820, 0.9454],\n",
      "        [0.4253, 0.4139, 0.0517, 0.0527]])\n",
      "tensor([[0.0591, 0.1539, 0.9029, 0.2346],\n",
      "        [0.5424, 0.7434, 0.9820, 0.9454],\n",
      "        [0.4253, 0.4139, 0.0517, 0.0527]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "m = nn.ReLU\n",
    "mm = nn.ReLU()\n",
    "x = torch.rand(3,4)\n",
    "print(x)\n",
    "print(mm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "65158c93-21a5-46b4-a9a2-c23aa345ab73",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReLU' object has no attribute 'ReLU'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [244]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReLU\u001b[49m\n\u001b[1;32m      2\u001b[0m mm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()\n",
      "File \u001b[0;32m~/.conda/envs/dnn/lib/python3.9/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ReLU' object has no attribute 'ReLU'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "4b792873-0b4c-4c53-93b8-727fc71e0ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3922, 0.8384, 0.9527, 0.9151],\n",
      "        [0.2924, 0.7863, 0.4554, 0.0034],\n",
      "        [0.7606, 0.6014, 0.6268, 0.2857]])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [243]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmm\u001b[49m(x))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mm' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "2632b991-d278-43f9-adc6-3e865f3f22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-2) :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2c5e488b-f844-4073-9f65-9ac6ec9684f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.1207+6.0961j])\n",
      "tensor([8.9406+3.6095j])\n",
      "tensor([63.6628+22.0041j])\n",
      "tensor([41.6587+80.2049j])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1,dtype=torch.cfloat)*10\n",
    "b = torch.rand(1,dtype=torch.cfloat)*10\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "c = a.real*b.real + 1j*a.imag*b.imag\n",
    "d = a*b\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651a783-ab6e-4834-af64-68e8226cbc78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
